âœ… `README.md`

````markdown
ğŸ¤– AI FAQ Chatbot (LangChain + FastAPI)

This project is an end-to-end **AI-powered FAQ chatbot** that can answer domain-specific questions using a custom knowledge base. It uses:

- âœ… [FastAPI](https://fastapi.tiangolo.com/) for the backend
- âœ… [LangChain](https://www.langchain.com/) for chaining logic and question-answering
- âœ… [ChromaDB](https://www.trychroma.com/) as the vector store
- âœ… [Hugging Face Transformers](https://huggingface.co/) models for LLM and embeddings
- âœ… [JWT Auth](https://jwt.io/) for authentication
- âœ… Docker-ready setup (optional)
- âœ… Simple frontend with HTML/CSS/JS

---

ğŸš€ Features

- ğŸ” User authentication with JWT tokens
- ğŸ§  Vector-based search over your own data
- ğŸ’¬ Secure chat interface powered by Hugging Face models
- âš™ï¸ Modular backend using FastAPI
- ğŸ“¦ Easily deployable with Docker

---

ğŸ§© Tech Stack

| Component     | Tool                          |
|---------------|-------------------------------|
| Backend       | FastAPI, Python 3.10+         |
| LLM & Embeds  | HuggingFace, LangChain        |
| Vector Store  | ChromaDB                      |
| Auth          | OAuth2 + JWT (Bearer Tokens)  |
| Frontend      | HTML + CSS + JavaScript       |
| Deployment    | Docker, Railway/Render/EC2    |

---

ğŸ› ï¸ Installation & Setup

 1. ğŸ“¦ Clone the Repo

```bash
git clone https://github.com/yourusername/ai-faq-chatbot.git
cd ai-faq-chatbot
````

2. ğŸ Create & Activate Virtual Env

```bash
python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. ğŸ“š Install Dependencies

```bash
pip install -r requirements.txt
```

Make sure to also install `chromadb` and `transformers`:

```bash
pip install chromadb transformers accelerate
```

If you're using M1/M2 Mac and get MPS warnings, update `torch`:

```bash
pip install --upgrade torch torchvision torchaudio
```

---

 4. âš™ï¸ Environment Variables

Edit `backend/app/config.py` and set your:

```python
SECRET_KEY = "your-secret-key"
ALGORITHM = "HS256"
ACCESS_TOKEN_EXPIRE_MINUTES = 30
```

---

5. ğŸ§  Prepare Vector DB

Before running the app, ensure you have ingested your documents into ChromaDB. If not, create an ingestion script and run it once.

```bash
python ingest.py  # Make sure it saves to `vectorstore/chroma/`
```

---

6. ğŸš¦ Run Backend API

```bash
uvicorn backend.app.main:app --reload
```

This will start the FastAPI app at: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

7. ğŸ’» Open the Frontend

The root FastAPI path serves the HTML UI from `frontend/`:

```
ğŸ“ frontend/
 â”œâ”€â”€ index.html
 â”œâ”€â”€ style.css
 â””â”€â”€ app.js
```

Just open [http://localhost:8000](http://localhost:8000) in your browser.

---

ğŸ” Authentication

Use the default credentials to log in:

* **Username:** `admin`
* **Password:** `admin123`

It will return a `Bearer Token` used in headers for accessing the `/chat` route.

---

ğŸ³ Docker (Optional)

To run inside Docker:

```bash
docker build -t ai-faq-chatbot .
docker run -p 8000:8000 ai-faq-chatbot
```

---

ğŸ“ Project Structure

```
ai-faq-chatbot/
â”‚
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ main.py         # FastAPI app
â”‚   â”‚   â”œâ”€â”€ auth.py         # JWT Auth logic
â”‚   â”‚   â”œâ”€â”€ chat.py         # LangChain + Chroma logic
â”‚   â”‚   â””â”€â”€ config.py       # Secrets and config
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ style.css
â”‚   â””â”€â”€ app.js
â”‚
â”œâ”€â”€ vectorstore/            # Chroma vector DB
â”œâ”€â”€ Dockerfile              # Optional Docker support
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ LICENSE
```

---
ğŸ“œ License

This project is licensed under the **MIT License**. See [`LICENSE`](./LICENSE) for details.

---
 
ğŸ¤ Contributing

PRs welcome! If you find bugs or want to suggest improvements, open an issue or submit a pull request.

---

ğŸ“¬ Contact

Made with by [Jenish Shekhada](mailto:your-email@example.com)
